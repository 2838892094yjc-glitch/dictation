#!/usr/bin/env python3
"""
ä»»åŠ¡6åŠŸèƒ½æ¼”ç¤ºï¼šè¯åº“å¯¼å…¥/å¯¼å‡º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°å¢çš„å¯¼å…¥å¯¼å‡ºåŠŸèƒ½
"""
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from data.vocabulary_store import VocabularyStore


def demo_import_export():
    """æ¼”ç¤ºå¯¼å…¥å¯¼å‡ºåŠŸèƒ½"""
    print("=" * 70)
    print("ä»»åŠ¡6åŠŸèƒ½æ¼”ç¤ºï¼šè¯åº“å¯¼å…¥/å¯¼å‡º")
    print("=" * 70)

    store = VocabularyStore()

    # æ¼”ç¤º1: æŸ¥çœ‹é¢„ç½®è¯åº“
    print("\nã€æ¼”ç¤º1ã€‘æŸ¥çœ‹é¢„ç½®è¯åº“")
    print("-" * 70)
    builtin_vocabs = store.list_builtin_vocabularies()
    print(f"ç³»ç»Ÿé¢„ç½®äº† {len(builtin_vocabs)} ä¸ªè¯åº“ï¼š\n")

    for i, vocab in enumerate(builtin_vocabs, 1):
        print(f"{i}. {vocab['name']}")
        print(f"   ğŸ“ å•è¯æ•°é‡: {vocab['word_count']}")
        print(f"   ğŸ“„ æè¿°: {vocab.get('description', 'æ— ')}")
        print(f"   ğŸ“‚ æ–‡ä»¶: {os.path.basename(vocab['file_path'])}")
        print()

    # æ¼”ç¤º2: åŠ è½½é¢„ç½®è¯åº“
    print("\nã€æ¼”ç¤º2ã€‘åŠ è½½é¢„ç½®è¯åº“")
    print("-" * 70)
    if builtin_vocabs:
        vocab = builtin_vocabs[0]
        print(f"æ­£åœ¨åŠ è½½: {vocab['name']}")
        result = store.load_builtin_vocabulary(vocab['file_path'], "æ¼”ç¤º_" + vocab['name'])
        if result:
            print(f"âœ… æˆåŠŸåŠ è½½è¯åº“: {result['name']}")
            print(f"   åŒ…å« {result['word_count']} ä¸ªå•è¯")

            # æ˜¾ç¤ºå‰5ä¸ªå•è¯
            loaded = store.load_vocabulary(result['name'])
            if loaded:
                print(f"\n   å‰5ä¸ªå•è¯é¢„è§ˆ:")
                for i, word in enumerate(loaded['words'][:5], 1):
                    print(f"   {i}. {word['en']} - {word['cn']}")

    # æ¼”ç¤º3: åˆ›å»ºè‡ªå®šä¹‰è¯åº“å¹¶å¯¼å‡º
    print("\n\nã€æ¼”ç¤º3ã€‘åˆ›å»ºè‡ªå®šä¹‰è¯åº“å¹¶å¯¼å‡º")
    print("-" * 70)
    custom_words = [
        {"en": "hello", "cn": "ä½ å¥½", "checked": False},
        {"en": "world", "cn": "ä¸–ç•Œ", "checked": False},
        {"en": "python", "cn": "èŸ’è›‡ï¼›Pythonè¯­è¨€", "checked": False},
        {"en": "code", "cn": "ä»£ç ", "checked": False},
        {"en": "learn", "cn": "å­¦ä¹ ", "checked": False}
    ]

    print("åˆ›å»ºè¯åº“: æ¼”ç¤ºè¯åº“")
    store.save_vocabulary("æ¼”ç¤ºè¯åº“", custom_words)
    print(f"âœ… å·²ä¿å­˜ {len(custom_words)} ä¸ªå•è¯\n")

    # å¯¼å‡ºä¸ºä¸åŒæ ¼å¼
    formats = [
        ("JSON", "/tmp/demo_vocab.json", store.export_to_json),
        ("TXT", "/tmp/demo_vocab.txt", store.export_to_txt),
        ("CSV", "/tmp/demo_vocab.csv", store.export_to_csv)
    ]

    for format_name, path, export_func in formats:
        success = export_func("æ¼”ç¤ºè¯åº“", path)
        if success:
            size = os.path.getsize(path)
            print(f"âœ… {format_name}æ ¼å¼å¯¼å‡ºæˆåŠŸ")
            print(f"   æ–‡ä»¶: {path}")
            print(f"   å¤§å°: {size} å­—èŠ‚")

            # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹é¢„è§ˆ
            if format_name == "TXT":
                with open(path, 'r', encoding='utf-8') as f:
                    content = f.read()
                print(f"   å†…å®¹é¢„è§ˆ:")
                for line in content.split('\n')[:3]:
                    if line.strip():
                        print(f"   {line}")
            print()

    # æ¼”ç¤º4: å¯¼å…¥è¯åº“
    print("\nã€æ¼”ç¤º4ã€‘å¯¼å…¥è¯åº“")
    print("-" * 70)
    print("ä»TXTæ–‡ä»¶å¯¼å…¥è¯åº“...")
    result = store.import_from_txt("/tmp/demo_vocab.txt", "æ¼”ç¤º_å¯¼å…¥çš„è¯åº“")
    if result:
        print(f"âœ… å¯¼å…¥æˆåŠŸ: {result['name']}")
        print(f"   å•è¯æ•°é‡: {result['word_count']}")

        # éªŒè¯å¯¼å…¥çš„å†…å®¹
        loaded = store.load_vocabulary(result['name'])
        if loaded:
            print(f"\n   å¯¼å…¥çš„å•è¯:")
            for i, word in enumerate(loaded['words'], 1):
                print(f"   {i}. {word['en']} - {word['cn']}")

    # æ¼”ç¤º5: æ ¼å¼è½¬æ¢
    print("\n\nã€æ¼”ç¤º5ã€‘æ ¼å¼è½¬æ¢ç¤ºä¾‹")
    print("-" * 70)
    print("æ¼”ç¤ºå¦‚ä½•å°†JSONæ ¼å¼è½¬æ¢ä¸ºTXTæ ¼å¼ï¼š")
    print("1. å¯¼å…¥JSONæ–‡ä»¶")
    print("2. å¯¼å‡ºä¸ºTXTæ–‡ä»¶")
    print()

    # ä½¿ç”¨é¢„ç½®è¯åº“è¿›è¡Œè½¬æ¢
    if builtin_vocabs:
        vocab = builtin_vocabs[0]
        print(f"æºæ–‡ä»¶: {os.path.basename(vocab['file_path'])} (JSON)")

        # å¯¼å…¥
        result = store.import_from_json(vocab['file_path'], "è½¬æ¢æµ‹è¯•")
        if result:
            # å¯¼å‡ºä¸ºTXT
            txt_path = "/tmp/converted.txt"
            store.export_to_txt("è½¬æ¢æµ‹è¯•", txt_path)
            print(f"ç›®æ ‡æ–‡ä»¶: {os.path.basename(txt_path)} (TXT)")
            print(f"âœ… è½¬æ¢å®Œæˆ")

            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å¯¹æ¯”
            json_size = os.path.getsize(vocab['file_path'])
            txt_size = os.path.getsize(txt_path)
            print(f"\næ–‡ä»¶å¤§å°å¯¹æ¯”:")
            print(f"  JSON: {json_size} å­—èŠ‚")
            print(f"  TXT:  {txt_size} å­—èŠ‚")
            print(f"  å‹ç¼©ç‡: {(1 - txt_size/json_size)*100:.1f}%")

    # æ¸…ç†æ¼”ç¤ºæ•°æ®
    print("\n\nã€æ¸…ç†ã€‘åˆ é™¤æ¼”ç¤ºæ•°æ®")
    print("-" * 70)
    demo_vocabs = ["æ¼”ç¤ºè¯åº“", "æ¼”ç¤º_å¯¼å…¥çš„è¯åº“", "è½¬æ¢æµ‹è¯•"]
    for vocab in builtin_vocabs:
        demo_vocabs.append("æ¼”ç¤º_" + vocab['name'])

    for name in demo_vocabs:
        if store.vocabulary_exists(name):
            store.delete_vocabulary(name)
            print(f"âœ… å·²åˆ é™¤: {name}")

    print("\n" + "=" * 70)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 70)

    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. åœ¨Streamlitç•Œé¢ä¸­ï¼Œè¿›å…¥'è¯åº“ç®¡ç†'é¡µé¢")
    print("2. ç‚¹å‡»'ğŸ“¥ğŸ“¤ å¯¼å…¥/å¯¼å‡º'åŒºåŸŸ")
    print("3. é€‰æ‹©ç›¸åº”çš„æ ‡ç­¾é¡µè¿›è¡Œæ“ä½œ")
    print("4. é¢„ç½®è¯åº“å¯ä»¥ç›´æ¥åŠ è½½ä½¿ç”¨")
    print("5. æ”¯æŒJSONã€TXTã€CSVä¸‰ç§æ ¼å¼äº’ç›¸è½¬æ¢")


if __name__ == "__main__":
    try:
        demo_import_export()
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
